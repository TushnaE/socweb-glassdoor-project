{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the necessary code to get the counts and metrics for each company and then runs it through the various ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow\n",
    "import tflearn\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.svm import LinearSVR\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'C:/Users/Chaitu Konjeti/socweb-glassdoor-project/REVIEWS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaitu Konjeti\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "all_metrics = {}\n",
    "\n",
    "metrics_file = pd.read_csv('metrics.csv')\n",
    "\n",
    "# get all the proper metrics from the metrics file\n",
    "for row in metrics_file.index:\n",
    "    #print(int(metrics_file['Data Year - Fiscal'][row]))\n",
    "    if metrics_file['Company Name'][row] not in all_metrics.keys():\n",
    "        all_metrics[metrics_file['Company Name'][row]] = []\n",
    "        if not math.isnan(metrics_file['Gross Profit (Loss)'][row]) and not math.isnan(int(metrics_file['Data Year - Fiscal'][row])) and not int(metrics_file['Data Year - Fiscal'][row]) != '0':\n",
    "            all_metrics[metrics_file['Company Name'][row]].append((int(metrics_file['Gross Profit (Loss)'][row]), str(int(metrics_file['Data Year - Fiscal'][row]))))\n",
    "    else:\n",
    "        if not math.isnan(metrics_file['Gross Profit (Loss)'][row]) and not math.isnan(int(metrics_file['Data Year - Fiscal'][row])):\n",
    "            all_metrics[metrics_file['Company Name'][row]].append((int(metrics_file['Gross Profit (Loss)'][row]), str(int(metrics_file['Data Year - Fiscal'][row]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(sentences):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = analyzer.polarity_scores(sentences)\n",
    "#     print(\"{:-<65} {}\".format(sentences, str(vs['compound'])))\n",
    "    return vs['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_and_metrics(dir):\n",
    "\n",
    "    metrics = []\n",
    "    list_of_posts = []\n",
    "    X = []\n",
    "    sentiments = []\n",
    "\n",
    "    #iterate through all files in the directory\n",
    "    for filename in os.listdir(dir):\n",
    "        print(filename)\n",
    "        df = pd.read_csv(dir + filename, header=0)\n",
    "\n",
    "        #get dates and pros columns from data file\n",
    "        dates = df['date']\n",
    "        pros = df['pros']\n",
    "\n",
    "        #get the list of years for all the posts in the file and create a dictionary with years as the keys\n",
    "        years = [date.split(' ')[3] for date in dates]\n",
    "        corpus = {key: '' for key in set(years)}\n",
    "\n",
    "        #add the post to the proper year in the dictionary\n",
    "        for date, pro in zip(years, pros):\n",
    "            corpus[date] += pro + ' '\n",
    "\n",
    "        #sort the keys in order\n",
    "        keys = sorted(corpus)\n",
    "\n",
    "        company_name = filename.split('.')[0]\n",
    "\n",
    "        metric_years = [val[1] for val in set(all_metrics[company_name]) if val[1] in years]\n",
    "\n",
    "        metrics.extend([val[0] for val in set(all_metrics[company_name]) if val[1] in years])\n",
    "\n",
    "        #only use the metrics from years that present in the datafile\n",
    "        for key in keys:\n",
    "            if key in metric_years:\n",
    "                sentiments.append(get_sentiment(corpus[key]))\n",
    "                list_of_posts.append(corpus[key])\n",
    "    #creates count vectorizer for posts\n",
    "    count_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 3))\n",
    "    counts = count_vectorizer.fit_transform(list_of_posts)\n",
    "\n",
    "    #creates Tfidf vectorizer for posts\n",
    "    tfid_vectorizer = TfidfVectorizer(ngram_range=(1, 3), analyzer='word')\n",
    "    tfid = tfid_vectorizer.fit_transform(list_of_posts).toarray()\n",
    "    \n",
    "    i = 0\n",
    "    for sentiment in sentiments:\n",
    "        X.append(np.append(tfid[i], [sentiment]))\n",
    "        \n",
    "    X = np.asarray(X)\n",
    "    metrics = np.asarray(metrics)\n",
    "    \n",
    "    return  X, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMERICAN AIRLINES GROUP INC.csv\n",
      "APPLE INC.csv\n",
      "AVNET INC.csv\n",
      "BUTLER NATIONAL CORP.csv\n",
      "CPI CORP.csv\n",
      "CVD EQUIPMENT CORP.csv\n",
      "DELPHAX TECHNOLOGIES INC.csv\n",
      "DELUXE CORP.csv\n",
      "KONARED CORP.csv\n",
      "MATERION CORP.csv\n"
     ]
    }
   ],
   "source": [
    "X, y = get_counts_and_metrics(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 14032)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaitu Konjeti\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6458333333333334"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rff_clf = RandomForestClassifier(max_depth=5)\n",
    "rff_clf.fit(X_train, y_train)\n",
    "rff_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0, 14485, 45640,    21, 15574,   224, 15574,     0,\n",
       "       13945, 45640,  1059,    16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = (rff_clf.predict(X_test))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18628.239280519985"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_test, pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04552800896937259"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13765.78771973, 21002.88098145, 20936.61132812, 20703.52539062,\n",
       "       19933.42724609,  1547.05151367, 20360.75170898, -1791.56335449,\n",
       "       20820.06835938, 20529.85339355, 20625.82995605, 21057.72473145,\n",
       "       20879.48242188])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = lr_clf.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17674.598844952823"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_test, pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "gnb_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   18,     0,     0,     0,     0,    16, 71061,    14,     0,\n",
       "           0,     0,  1059,     0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = gnb_clf.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7767.347299878066"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_test, pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04552800896937259"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr_clf = LinearRegression()\n",
    "logr_clf.fit(X_train, y_train)\n",
    "logr_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13765.78771973, 21002.88098145, 20936.61132812, 20703.52539062,\n",
       "       19933.42724609,  1547.05151367, 20360.75170898, -1791.56335449,\n",
       "       20820.06835938, 20529.85339355, 20625.82995605, 21057.72473145,\n",
       "       20879.48242188])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = logr_clf.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17674.598844952823"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_test, pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3090862925328073"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = LinearSVR()\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49.09886432, 55.192299  , 55.13650184, 54.94024976, 54.29184828,\n",
       "       38.81102244, 54.65164376, 36.        , 55.0383758 , 54.79402272,\n",
       "       54.8748324 , 55.23847596, 55.08840084])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = svm_clf.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1572.9350279212385"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_test, pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = 100\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 100, 32)           32000     \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 85,301\n",
      "Trainable params: 85,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 48 samples, validate on 13 samples\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 3s 55ms/step - loss: 1302795647.5826 - accuracy: 0.0000e+00 - val_loss: 2561348.0923 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 2s 41ms/step - loss: 1302520392.7672 - accuracy: 0.0000e+00 - val_loss: 2549890.6199 - val_accuracy: 0.1538\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 2s 42ms/step - loss: 1302380458.8360 - accuracy: 0.0625 - val_loss: 2542371.6183 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 2s 41ms/step - loss: 1302277356.8988 - accuracy: 0.0208 - val_loss: 2536518.0224 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 2s 43ms/step - loss: 1302185231.4929 - accuracy: 0.0000e+00 - val_loss: 2531031.9996 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 2s 41ms/step - loss: 1302098384.5325 - accuracy: 0.0000e+00 - val_loss: 2525132.3167 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 1302001960.4679 - accuracy: 0.0000e+00 - val_loss: 2520292.6763 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 2s 48ms/step - loss: 1301916903.0823 - accuracy: 0.0000e+00 - val_loss: 2514982.4550 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 2s 44ms/step - loss: 1301828485.0626 - accuracy: 0.0000e+00 - val_loss: 2509876.6443 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 2s 50ms/step - loss: 1301744063.1053 - accuracy: 0.0000e+00 - val_loss: 2504574.3139 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2298b1a67c8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vector_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000, embedding_vector_length, input_length=100))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
